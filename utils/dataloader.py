import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import sys
import random

# ç¡®ä¿èƒ½å¯¼å…¥ config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

class MSTNetDataset(Dataset):
    def __init__(self, mode='train', split_ratio=0.8):
        """
        MSTNet æ•°æ®é›†åŠ è½½å™¨
        Args:
            mode: 'train' æˆ– 'val'
            split_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        """
        self.temp_dir = config.TEMP_FEATURE_DIR
        self.max_len = config.MAX_SEQ_LEN

        # 1. æ‰«ææ‰€æœ‰ä¸»ç‰¹å¾æ–‡ä»¶ (æŽ’é™¤å¸¦ _motion çš„)
        all_files = sorted([
            f for f in os.listdir(self.temp_dir)
            if f.endswith('.npy') and '_motion' not in f
        ])

        if not all_files:
            raise FileNotFoundError(f"âŒ åœ¨ {self.temp_dir} æ²¡æ‰¾åˆ°ç‰¹å¾æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")

        # 2. å…¨å±€æ‰“ä¹±æ•°æ® (ä½¿ç”¨ç§å­ä¿è¯å®žéªŒå¯å¤çŽ°)
        random.seed(config.SEED)
        random.shuffle(all_files)

        # 3. åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
        split_idx = int(len(all_files) * split_ratio)
        if mode == 'train':
            self.file_list = all_files[:split_idx]
        else:
            self.file_list = all_files[split_idx:]

        print(f"ðŸ“¦ MSTNet Dataset [{mode}]: åŠ è½½äº† {len(self.file_list)} ä¸ªæ ·æœ¬")

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        # --- 1. å®šä½æ–‡ä»¶è·¯å¾„ ---
        visual_file = self.file_list[idx]
        subject_id = visual_file.replace('.npy', '')
        motion_file = f"{subject_id}_motion.npy"

        visual_path = os.path.join(self.temp_dir, visual_file)
        motion_path = os.path.join(self.temp_dir, motion_file)

        # --- 2. åŠ è½½å¹¶é˜²å¾¡æ€§æ‹·è´æ•°æ® ---
        # åŠ ä¸Š .copy() ç¡®ä¿å†…å­˜ç‹¬ç«‹ï¼Œé˜²æ­¢ numpy å†…å­˜æ˜ å°„å¯¼è‡´çš„é”å®šé—®é¢˜
        v_data = np.load(visual_path, allow_pickle=True).item()
        m_data = np.load(motion_path, allow_pickle=True).item()

        # æ˜¾å¼æ‹·è´å¹¶è½¬æ¢ä¸º float32ï¼Œç¡®ä¿è®¡ç®—ç²¾åº¦
        local_feat = v_data['local'].astype(np.float32).copy()
        global_feat = v_data['global'].astype(np.float32).copy()
        motion_feat = m_data['motion'].astype(np.float32).copy()
        physio_feat = m_data['physio'].astype(np.float32).copy()

        # --- 3. ä¿®æ­£ï¼šæ—¶é—´æˆ³å½’ä¸€åŒ– (é¿å…åŽŸåœ°æ“ä½œ) ---
        t_raw = physio_feat[:, 2]
        t_norm = t_raw / config.VIDEO_DURATION
        physio_feat[:, 2] = t_norm

        # æ ‡ç­¾é€»è¾‘ï¼šID å¤§äºŽæ€»æ•°ä¸€åŠçš„è®¾ä¸º 1
        label = 1 if int(subject_id) > (config.NUM_SIMULATED_PEOPLE // 2) else 0

        # --- 4. ç»Ÿä¸€æ—¶åºå¤„ç† (æˆªæ–­æˆ–å¡«å……) ---
        curr_len = local_feat.shape[0]

        if curr_len >= self.max_len:
            local_feat = local_feat[:self.max_len]
            global_feat = global_feat[:self.max_len]
            motion_feat = motion_feat[:self.max_len]
            physio_feat = physio_feat[:self.max_len]
            mask = torch.zeros(self.max_len, dtype=torch.bool)
        else:
            pad_len = self.max_len - curr_len
            local_feat = np.pad(local_feat, ((0, pad_len), (0, 0)))
            global_feat = np.pad(global_feat, ((0, pad_len), (0, 0)))
            motion_feat = np.pad(motion_feat, ((0, pad_len), (0, 0)))
            physio_feat = np.pad(physio_feat, ((0, pad_len), (0, 0)))
            mask = torch.zeros(self.max_len, dtype=torch.bool)
            mask[curr_len:] = True

        # --- 5. æ‰“åŒ…è¿”å›ž ---
        return {
            "temporal_input": {
                "local": torch.from_numpy(local_feat).float(),
                "global": torch.from_numpy(global_feat).float(),
                "physio": torch.from_numpy(physio_feat).float()
            },
            "motion_input": torch.from_numpy(motion_feat).float(),
            "gnn_input": {
                "local": torch.from_numpy(local_feat).float(),
                "coords": torch.from_numpy(physio_feat).float()
            },
            "mask": mask,
            "label": torch.tensor(label, dtype=torch.long)
        }

def get_mstnet_loaders(batch_size=None):
    if batch_size is None:
        batch_size = config.BATCH_SIZE

    train_ds = MSTNetDataset(mode='train')
    val_ds = MSTNetDataset(mode='val')

    train_loader = DataLoader(
        train_ds,
        batch_size=batch_size,
        shuffle=True,  # è®­ç»ƒ Batch å†…æ‰“ä¹±
        num_workers=config.NUM_WORKERS
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=batch_size,
        shuffle=False,
        num_workers=config.NUM_WORKERS
    )

    return train_loader, val_loader