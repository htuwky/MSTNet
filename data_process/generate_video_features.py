import sys
import os
import glob
import pandas as pd
import numpy as np
import torch
import clip
from PIL import Image
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
import multiprocessing
import gc

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config

# ================= é…ç½® =================
BATCH_SIZE = 256
NUM_WORKERS = 4  # 0 æ˜¯æœ€ç¨³çš„ï¼Œå¦‚æœå¤šè¿›ç¨‹æŠ¥é”™è¯·æ”¹ä¸º0
TEMP_SAVE_DIR = os.path.join(config.OUTPUT_DIR, 'temp_features')

# ========================================

def get_frame_idx(timestamp):
    return int(timestamp * config.VIDEO_FPS) + 1


class GazeDataset(Dataset):
    def __init__(self, df, frame_dir, preprocess, crop_size, video_w, video_h):
        # [å…³é”®ä¿®æ”¹] è¿‡æ»¤æ‰åŒ…å« NaN (ç©ºå€¼) çš„è¡Œï¼Œé˜²æ­¢çœ¨çœ¼æ•°æ®å¯¼è‡´ç¨‹åºå´©æºƒ
        self.data = df.dropna(subset=['Gaze_X', 'Gaze_Y', 'Timestamp']).to_dict('records')
        self.frame_dir = frame_dir
        self.preprocess = preprocess
        self.crop_size = crop_size
        self.video_w = video_w
        self.video_h = video_h
        self.cache = {'idx': -1, 'img': None}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data[idx]
        ts = row['Timestamp']

        target_frame_idx = get_frame_idx(ts)

        # --- 1. è¯»å›¾ ---
        current_img = self.cache['img']
        if self.cache['idx'] != target_frame_idx:
            frame_path = os.path.join(self.frame_dir, f"frame_{target_frame_idx:05d}.png")
            if os.path.exists(frame_path):
                try:
                    current_img = Image.open(frame_path).convert("RGB")
                    self.cache['idx'] = target_frame_idx
                    self.cache['img'] = current_img
                except:
                    if current_img is None: current_img = Image.new("RGB", (self.video_w, self.video_h), (0, 0, 0))
            else:
                if current_img is None: current_img = Image.new("RGB", (self.video_w, self.video_h), (0, 0, 0))

        # --- 2. åæ ‡å¤„ç† (å¤„ç†æº¢å‡º) ---
        w, h = current_img.size
        # ç¡®ä¿åæ ‡æ˜¯æœ‰æ•ˆçš„ floatï¼Œé˜²æ­¢å¥‡æ€ªçš„æ ¼å¼
        try:
            raw_x = float(row['Gaze_X'])
            raw_y = float(row['Gaze_Y'])
        except:
            raw_x, raw_y = 0.5, 0.5  # æç«¯å®¹é”™ï¼šæ”¾ä¸­é—´

        gx = int(raw_x * self.video_w)
        gy = int(raw_y * self.video_h)

        # --- 3. å®‰å…¨è£å‰ª (Safe Crop - Zero Padding) ---
        # å¦‚æœåæ ‡å¯¼è‡´è£å‰ªæ¡†è¶…å‡ºäº†å›¾åƒè¾¹ç•Œï¼Œè¿™é‡Œä¼šè‡ªåŠ¨è¡¥é»‘è¾¹
        half = self.crop_size // 2
        # å¿«é€Ÿåˆ¤æ–­ï¼šå¦‚æœåœ¨è¾¹ç•Œå†…
        if gx - half >= 0 and gy - half >= 0 and gx + half <= w and gy + half <= h:
            patch = current_img.crop((gx - half, gy - half, gx + half, gy + half))
        else:
            # å¦‚æœåœ¨è¾¹ç•Œå¤–ï¼šåˆ›å»ºå…¨é»‘åº•å›¾ï¼ŒæŠŠèƒ½åˆ‡åˆ°çš„éƒ¨åˆ†è´´ä¸Šå»
            patch = Image.new("RGB", (self.crop_size, self.crop_size), (0, 0, 0))

            # è®¡ç®—åŸå›¾ä¸Šçš„è£å‰ªåŒºåŸŸ
            src_left = max(0, gx - half)
            src_top = max(0, gy - half)
            src_right = min(w, gx + half)
            src_bottom = min(h, gy + half)

            # è®¡ç®—è´´åˆ°é»‘å›¾ä¸Šçš„ä½ç½®
            dst_left = max(0, -(gx - half))
            dst_top = max(0, -(gy - half))

            if src_right > src_left and src_bottom > src_top:
                crop_part = current_img.crop((src_left, src_top, src_right, src_bottom))
                patch.paste(crop_part, (dst_left, dst_top))

        return self.preprocess(patch), self.preprocess(current_img), ts


def main():
    print("=" * 60)
    print(f"ğŸš€ MSTNet Feature Extraction (Safe Mode - No Merge)")
    print("=" * 60)

    # åªåˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ï¼Œä¸å†åˆ›å»ºå¤§æ–‡ä»¶ç›®å½•
    os.makedirs(TEMP_SAVE_DIR, exist_ok=True)

    device = config.DEVICE if torch.cuda.is_available() else "cpu"
    print(f"ğŸ”§ Device: {device} | Batch: {BATCH_SIZE}")

    print("â³ Loading CLIP model...")
    model, preprocess = clip.load(config.CLIP_MODEL_NAME, device=device)
    model.eval()

    csv_files = glob.glob(os.path.join(config.CSV_DIR, '*.csv'))
    print(f"ğŸ“‚ Found {len(csv_files)} CSV files to process.")

    # === é˜¶æ®µ 1ï¼šåˆ†ç‰‡æå– ===
    for csv_path in tqdm(csv_files, desc="Extracting Features"):
        subject_id = os.path.basename(csv_path).split('.')[0]
        save_path = os.path.join(TEMP_SAVE_DIR, f"{subject_id}.npy")

        # æ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°æ­£å¸¸ï¼Œè·³è¿‡
        if os.path.exists(save_path):
            continue

        try:
            df = pd.read_csv(csv_path)
            dataset = GazeDataset(df, config.FRAME_DIR, preprocess, config.CROP_SIZE, config.VIDEO_W, config.VIDEO_H)

            if len(dataset) == 0: continue

            dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS,
                                    pin_memory=False)

            local_list, global_list, timestamp_list = [], [], []

            with torch.no_grad():
                with torch.amp.autocast('cuda'):
                    for b_local, b_global, b_ts in dataloader:
                        b_local = b_local.to(device)
                        b_global = b_global.to(device)

                        l = model.encode_image(b_local)
                        g = model.encode_image(b_global)

                        # å½’ä¸€åŒ–ç‰¹å¾
                        l /= l.norm(dim=-1, keepdim=True)
                        g /= g.norm(dim=-1, keepdim=True)

                        # è½¬å­˜ä¸º float16 èŠ‚çœç©ºé—´
                        local_list.append(l.cpu().numpy().astype(np.float16))
                        global_list.append(g.cpu().numpy().astype(np.float16))
                        timestamp_list.append(b_ts.numpy().astype(np.float64))

            if local_list:
                data_dict = {
                    'local': np.vstack(local_list),
                    'global': np.vstack(global_list),
                    'timestamp': np.concatenate(timestamp_list)
                }
                np.save(save_path, data_dict)

            # å†…å­˜å›æ”¶
            del dataset, dataloader, local_list, global_list, timestamp_list, data_dict, df
            gc.collect()
            torch.cuda.empty_cache()

        except Exception as e:
            print(f"\nâŒ Error processing {subject_id}: {e}")
            continue

    print("\n" + "=" * 60)
    print("âœ… Extraction Finished! All features saved in temp folder.")
    print(f"ğŸ“‚ Location: {TEMP_SAVE_DIR}")
    print("=" * 60)


if __name__ == "__main__":
    multiprocessing.freeze_support()
    main()