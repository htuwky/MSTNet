import os
import torch

# ================= 1. è·¯å¾„é…ç½® (Path Config) =================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# è¾“å…¥è·¯å¾„
CSV_DIR = os.path.join(BASE_DIR, 'dataset', 'eye_data')
FRAME_DIR = os.path.join(BASE_DIR, 'dataset', 'frames')

# è¾“å‡ºè·¯å¾„ (åªä¿ç•™åˆ†ç‰‡æ–‡ä»¶å¤¹ï¼Œåˆ é™¤äº†å¤§æ–‡ä»¶è·¯å¾„)
OUTPUT_DIR = os.path.join(BASE_DIR, 'dataset', 'output')
TEMP_FEATURE_DIR = os.path.join(OUTPUT_DIR, 'temp_features')

# ================= 2. æ•°æ®ä¸Žæ¨¡æ‹Ÿé…ç½® (Data & Simulation) =================
# [å…³é”®] æ¨¡æ‹Ÿæ•°æ®çš„æºå¤´æŽ§åˆ¶ï¼Œä¿®æ”¹è¿™é‡Œä¼šå½±å“ eye_data_product.py
NUM_SIMULATED_PEOPLE = 400 # æ¨¡æ‹Ÿäººæ•°
VIDEO_FPS = 23.0           # è§†é¢‘å¸§çŽ‡
EYE_SAMPLING_RATE = 60.0   # çœ¼åŠ¨é‡‡æ ·çŽ‡
VIDEO_DURATION = 343.0     # è§†é¢‘æ€»æ—¶é•¿(ç§’)ï¼Œç”¨äºŽæ—¶é—´æˆ³å½’ä¸€åŒ–

CLIP_MODEL_NAME = "ViT-B/32"
CROP_SIZE = 224
VIDEO_W = 960
VIDEO_H = 544

# ================= 3. æ¨¡åž‹æž¶æž„é…ç½® (Model Architecture) =================
# è¾“å…¥ç»´åº¦
CLIP_EMBED_DIM = 512      # Visual Dim
PHYSIO_INPUT_DIM = 3      # Physio Dim: (x, y, t)

# ç“¶é¢ˆå±‚ä¸Žèžåˆ
USE_BOTTLENECK = True     # å¼€å¯ MSTNet æ ¸å¿ƒç­–ç•¥
BOTTLENECK_DIM = 64       # åŽ‹ç¼©åˆ° 64 ç»´
BOTTLENECK_DIM_MOTION = 16
BOTTLENECK_DIM_GNN = 32
GNN_NODE_DIM = 12
HIDDEN_DIM = 128          # Transformer å†…éƒ¨ç»´åº¦

# Transformer ç»†èŠ‚
NUM_LAYERS = 2            # å±‚æ•°
NUM_HEADS = 4             # å¤´æ•°
FFN_EXPANSION_FACTOR = 4  # [æ–°å¢ž] FFNè†¨èƒ€ç³»æ•° (128 -> 512 -> 128)
DROPOUT = 0.5             # å¼ºåŠ› Dropout
FOURIER_SCALE = 10        # å‚…é‡Œå¶ç¼–ç ç¼©æ”¾

# åºåˆ—ä¸Žåˆ†ç±»
MAX_SEQ_LEN = 512         # åºåˆ—é•¿åº¦
NUM_CLASSES = 2           # äºŒåˆ†ç±»

# ================= 4. è¿è¡Œå‚æ•° (Hyperparameters) =================
# è®­ç»ƒå‚æ•°
BATCH_SIZE = 64           # è®­ç»ƒç”¨ (æ˜¾å­˜å ç”¨å¤§)
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-4
NUM_EPOCHS = 100

# ç‰¹å¾æå–å‚æ•°
EXTRACT_BATCH_SIZE = 256  # [æ–°å¢ž] æå–ç‰¹å¾ç”¨ (æ˜¾å­˜å ç”¨å°ï¼Œå¯ä»¥å¤§ä¸€ç‚¹)

# ç³»ç»Ÿå‚æ•°
NUM_WORKERS = 0           # Windows å»ºè®® 0
SEED = 42
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def print_config():
    print("="*60)
    print("ðŸ”§ MSTNet Configuration (Decoupled)")
    print("="*60)
    print(f"Device: {DEVICE}")
    print(f"Simulated People: {NUM_SIMULATED_PEOPLE}")
    print(f"Video Duration: {VIDEO_DURATION}s")
    print(f"Batch Sizes -> Train: {BATCH_SIZE} | Extract: {EXTRACT_BATCH_SIZE}")
    print("="*60)